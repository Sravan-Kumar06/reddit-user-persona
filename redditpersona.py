# -*- coding: utf-8 -*-
"""RedditPersona.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K8_u_ahtFixAIzXxM7CeSbjEf1rVdyQJ

##Required Dependencies
"""

!pip install praw python-dotenv requests

import os

"""### Create and write to .env"""

env_code = '''
REDDIT_CLIENT_ID=reddit_client_id
REDDIT_CLIENT_SECRET=reddit_client_secret
USER_AGENT=reddit-user-persona-app
OPENROUTER_API_KEY=openrouter_api_key
'''
#Added my personal secret keys and checked the code

with open(".env", "w") as f:
    f.write(env_code)

print(".env file created successfully with your API credentials.")

"""##Load Credentials and Importing API'S"""

from dotenv import load_dotenv
import openai
import praw

load_dotenv()

reddit = praw.Reddit(
    client_id=os.getenv("REDDIT_CLIENT_ID"),
    client_secret=os.getenv("REDDIT_CLIENT_SECRET"),
    user_agent=os.getenv("USER_AGENT"),
)

"""##Extract Reddit Data"""

import re

def extract_username(url):
    match = re.search(r'reddit\.com/user/([^/]+)/?', url)
    return match.group(1) if match else None

#  5. Fetch Reddit Posts & Comments
def fetch_user_data(username, limit=100):
    user = reddit.redditor(username)
    posts, comments = [], []

    try:
        for post in user.submissions.new(limit=limit):
            posts.append({
                "title": post.title,
                "body": post.selftext,
                "url": post.permalink
            })

        for comment in user.comments.new(limit=limit):
            comments.append({
                "body": comment.body,
                "url": comment.permalink
            })

        return posts, comments
    except Exception as e:
        print(f"Error fetching data: {e}")
        return [], []

"""##Persona Generation with GPT"""

import requests

def generate_persona(posts, comments):
    combined_data = "### POSTS ###\n"
    for p in posts:
        combined_data += f"Title: {p['title']}\nContent: {p['body']}\nURL: https://www.reddit.com{p['url']}\n\n"

    combined_data += "### COMMENTS ###\n"
    for c in comments:
        combined_data += f"Comment: {c['body']}\nURL: https://www.reddit.com{c['url']}\n\n"

    prompt = f"""
You are a helpful assistant.

Based on the following Reddit activity (posts and comments), generate a **User Persona**. Include:
- Name (can be made-up)
- Age Range
- Gender (if detectable)
- Occupation / Hobbies
- Interests
- Subreddits they frequent
- Writing Style or Tone
- Political / Cultural Opinions (if evident)
- Notable personality traits
- Cite at least one post or comment (with URL) for each insight.

REDDIT DATA:
{combined_data}
"""

    headers = {
        "Authorization": f"Bearer {os.getenv('OPENROUTER_API_KEY')}",
        "Content-Type": "application/json"
    }

    api_url = "https://openrouter.ai/api/v1/chat/completions"
    payload = {
        "model": "mistralai/mistral-7b-instruct",
        "messages": [
            {"role": "system", "content": "You are an expert in user profiling."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7,
        "max_tokens": 1500
    }

    response = requests.post(api_url, headers=headers, json=payload)
    if response.status_code == 200:
        return response.json()['choices'][0]['message']['content']
    else:
        print(f"Error: {response.status_code} - {response.json()}")
        return " Could not generate persona due to API error."

"""##Output file"""

def save_persona(username, persona_text):
    filename = f"{username}_persona.txt"
    with open(filename, "w", encoding="utf-8") as f:
        f.write(persona_text)
    return filename

"""##MAIN INTERFACE"""

input_url = input(" Enter Reddit Profile URL: ").strip()
username = extract_username(input_url)

if not username:
    print(" Invalid Reddit URL")
else:
    print(f" Fetching Reddit data for: {username} ...")
    posts, comments = fetch_user_data(username)

    if not posts and not comments:
        print(" No data found.")
    else:
        print(" Generating user persona...")
        persona = generate_persona(posts, comments)
        file = save_persona(username, persona)

        print("\n Persona Preview:\n")
        print(persona[:1500])